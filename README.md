# ğŸ“– Chunking Techniques in NLP and RAG

Chunking is the process of splitting large text into smaller, manageable pieces (chunks) that can be stored, searched, or processed efficiently.  
Itâ€™s especially important in **Retrieval-Augmented Generation (RAG)** and **document indexing**, since most LLMs have token limits.

---

## 1. Fixed-Size Chunking
- **Definition**: Break text into equal-sized chunks (by characters, words, or tokens).
- **Example**: Split every 500 tokens.
- **Pros**: Simple, fast, predictable.
- **Cons**: May cut sentences or paragraphs mid-way, losing semantic meaning.

```text
[Chunk 1: tokens 0â€“499]
[Chunk 2: tokens 500â€“999]
...
````

---

## 2. Overlapping Sliding Window

* **Definition**: Fixed-size chunks, but with overlap to preserve context across boundaries.
* **Example**: 500-token chunks with 100-token overlap.
* **Pros**: Reduces risk of missing context at chunk boundaries.
* **Cons**: Increases storage and retrieval costs.

```text
[Chunk 1: tokens 0â€“499]
[Chunk 2: tokens 400â€“899]  (100-token overlap)
[Chunk 3: tokens 800â€“1299]
```

---

## 3. Sentence-Based Chunking

* **Definition**: Use sentence boundaries to define chunks.
* **Example**: Group 3â€“5 sentences per chunk.
* **Pros**: Preserves natural meaning.
* **Cons**: Chunk size can vary widely; may not fit token limits.

```text
[Chunk 1: Sentence 1â€“5]
[Chunk 2: Sentence 6â€“10]
```

---

## 4. Paragraph-Based Chunking

* **Definition**: Split text by paragraphs.
* **Pros**: Maintains semantic grouping.
* **Cons**: Some paragraphs may be too long; others too short.

```text
[Chunk 1: Paragraph 1]
[Chunk 2: Paragraph 2]
```

---

## 5. Recursive Chunking (Hybrid)

* **Definition**: Start with large blocks, then break them down recursively if they exceed a threshold.
* **Example**: Split by sections â†’ paragraphs â†’ sentences â†’ words.
* **Pros**: Balances semantic structure and token constraints.
* **Cons**: More complex to implement.

---

## 6. Semantic Chunking (Embedding-Aware)

* **Definition**: Use embeddings or topic segmentation to find natural breakpoints (topic shifts, headings).
* **Pros**: Best semantic preservation; reduces irrelevant splits.
* **Cons**: Computationally expensive.

---

## ğŸ“Š Comparison Table

| Technique          | Preserves Meaning | Simplicity | Efficiency | Use Case             |
| ------------------ | ----------------- | ---------- | ---------- | -------------------- |
| Fixed-Size         | âŒ                 | âœ…          | âœ…          | Large raw text       |
| Overlapping Window | â–                 | âœ…          | â–          | Legal docs, research |
| Sentence-Based     | âœ…                 | âœ…          | âœ…          | Conversational text  |
| Paragraph-Based    | âœ…                 | âœ…          | â–          | Articles, reports    |
| Recursive Chunking | âœ…                 | â–          | â–          | Mixed documents      |
| Semantic Chunking  | âœ…âœ…                | âŒ          | âŒ          | Knowledge bases      |

---

## âœ… Best Practices

1. Choose chunking based on **document type** and **LLM token window**.
2. Always balance **chunk size** (too small = noisy retrieval, too large = token overflow).
3. Consider **overlaps** for context-heavy use cases.
4. For production RAG: **Recursive chunking + overlap** is often the sweet spot.

---

## ğŸš€ Interactive Comparison Tool

This project now includes a **Streamlit-based interactive comparison tool** to visualize and compare all chunking strategies side-by-side!

### Quick Start

1. **Install dependencies:**
   ```bash
   uv sync
   ```

2. **Run the Streamlit app:**
   ```bash
   streamlit run streamlit_app/app.py
   ```

3. **Use the app:**
   - Upload a text file or paste your content
   - Select multiple chunking strategies
   - Adjust parameters for each strategy
   - Compare results side-by-side with visualizations
   - Download chunked results

### Features

- ğŸ“Š **Visual Comparisons**: Charts showing number of chunks and size distributions
- âš™ï¸ **Configurable**: Adjust parameters for each strategy
- ğŸ“ **Detailed Views**: Preview individual chunks from each strategy
- ğŸ“¥ **Export**: Download chunked results as text files
- ğŸ”„ **Multiple Strategies**: Run and compare up to 6 different chunking methods

See `QUICKSTART.md` for detailed instructions and `streamlit_app/README.md` for full documentation.

---

## ğŸ“ Project Structure

```
chunking-strategies/
â”œâ”€â”€ 1-character-chunking/       # Fixed-size character chunking
â”œâ”€â”€ 2-recursive-character/      # Recursive character text splitter
â”œâ”€â”€ 3-document-specific/        # Document-type aware chunkers
â”‚   â”œâ”€â”€ markdown.py
â”‚   â”œâ”€â”€ python_splitter.py
â”‚   â””â”€â”€ language_splitter.py
â”œâ”€â”€ 4-semantic-chunking/        # Embedding-based semantic chunking
â”œâ”€â”€ 5-cluster-semantic-chunking/ # Global optimization semantic chunking
â”œâ”€â”€ streamlit_app/              # ğŸ†• Interactive comparison tool
â”‚   â”œâ”€â”€ app.py                  # Main Streamlit application
â”‚   â”œâ”€â”€ unified_chunkers.py     # Unified chunking interface
â”‚   â”œâ”€â”€ README.md               # App documentation
â”‚   â””â”€â”€ sample_text.txt         # Example text file
â”œâ”€â”€ pyproject.toml              # Dependencies
â”œâ”€â”€ QUICKSTART.md               # ğŸ†• Quick start guide
â””â”€â”€ README.md                   # This file

